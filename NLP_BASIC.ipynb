{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_BASIC.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIf5kIk6bz2g",
        "outputId": "988f4c0a-60fd-46c6-c700-80766c91efb5"
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "df= pd.read_csv('/content/drive/MyDrive/train.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7Yh_gBF3Lwz"
      },
      "source": [
        "#Analysis and Enhancement of corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "1Jl3Q-iZcHex",
        "outputId": "a806267f-1bfe-4808-ac10-5ee62b47732f"
      },
      "source": [
        "df['author'] = df['author'].fillna(\" \")\n",
        "df['text'] = df['text'].fillna(\" \") \n",
        "df['title'] = df['title'].fillna(\" \") \n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>Darrell Lucus</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
              "      <td>Daniel J. Flynn</td>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Why the Truth Might Get You Fired</td>\n",
              "      <td>Consortiumnews.com</td>\n",
              "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
              "      <td>Jessica Purkiss</td>\n",
              "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
              "      <td>Howard Portnoy</td>\n",
              "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... label\n",
              "0   0  ...     1\n",
              "1   1  ...     0\n",
              "2   2  ...     1\n",
              "3   3  ...     1\n",
              "4   4  ...     1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dLk6_QUcXXM",
        "outputId": "d85db77b-03af-4210-de63-a62c49d7be99"
      },
      "source": [
        "df['author'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     1957\n",
              "Pam Key                               243\n",
              "admin                                 193\n",
              "Jerome Hudson                         166\n",
              "Charlie Spiering                      141\n",
              "                                     ... \n",
              "Louise Story                            1\n",
              "Maximus Decimus Meridius                1\n",
              "Marc Santora and Samantha Schmidt       1\n",
              "Marianne Rohrlich                       1\n",
              "A Jew (UID 73270427)                    1\n",
              "Name: author, Length: 4202, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "KHwbYUYFcadH",
        "outputId": "1bf33d84-e8e7-4d0e-b0de-73fd66f779e2"
      },
      "source": [
        "df.groupby('label').describe()\n",
        "# data is evenly distributed, so we do not need to balance it."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"8\" halign=\"left\">id</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10387.0</td>\n",
              "      <td>10392.644171</td>\n",
              "      <td>5982.025154</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5225.5</td>\n",
              "      <td>10396.0</td>\n",
              "      <td>15565.5</td>\n",
              "      <td>20797.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10413.0</td>\n",
              "      <td>10406.338711</td>\n",
              "      <td>6027.288133</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5159.0</td>\n",
              "      <td>10403.0</td>\n",
              "      <td>15629.0</td>\n",
              "      <td>20799.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id                             ...                           \n",
              "         count          mean          std  ...      50%      75%      max\n",
              "label                                      ...                           \n",
              "0      10387.0  10392.644171  5982.025154  ...  10396.0  15565.5  20797.0\n",
              "1      10413.0  10406.338711  6027.288133  ...  10403.0  15629.0  20799.0\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X42bEAAQceCf"
      },
      "source": [
        "#seprating the label and concatenating the title, text and author. \n",
        "df.drop('label',axis=1)\n",
        "df['news_data'] = df['title'] + \" \" + df['author'] + \" \" + df['text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7mnc3cjcnF9",
        "outputId": "428e64bf-db44-4610-da10-99577af56ac4"
      },
      "source": [
        "#analysing the contcatenated data for lstm\n",
        "# the mean value of news data will be used later\n",
        "txt = [text for text in df.news_data]\n",
        "max_len_txt = 0\n",
        "txt_len = []\n",
        "for text in txt:\n",
        "    txt_len.append(len(text.split()))\n",
        "    max_len_txt = max(len(text.split()), max_len_txt)\n",
        "\n",
        "print('Max length of the fake_news_text:', max_len_txt)\n",
        "print('Mean length of the fake_news_text:', np.mean(txt_len))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length of the fake_news_text: 24245\n",
            "Mean length of the fake_news_text: 773.1286057692307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ54S0aMc05y"
      },
      "source": [
        "y=df['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43MvwwVd2nDb"
      },
      "source": [
        "#preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ-jJ9lsc5HL",
        "outputId": "e16a3b7d-fb21-4615-912f-d308bc48bb25"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import PorterStemmer\n",
        "porter=PorterStemmer()\n",
        "stop_word=stopwords.words('english')\n",
        "tokenized_sents=[]\n",
        "def preprocessing(text):\n",
        "  data=[]\n",
        "  for i in text:\n",
        "    sent=re.sub(r'[^a-zA-Z]', ' ', str(i))\n",
        "    sent=sent.lower()\n",
        "    sent_token=sent.split()\n",
        "    sent_stem=[]\n",
        "    for j in sent_token:\n",
        "      if j not in stop_word:\n",
        "        sent_stem.append(j)\n",
        "    tokenized_sents.append(sent_stem)\n",
        "    sent=' '.join(sent_stem)\n",
        "    data.append(sent)\n",
        "  return data\n",
        "\n",
        "data=preprocessing(df['news_data'])\n",
        "print(\"clean data\")\n",
        "print(data[:10000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t7UUQZG2rSI"
      },
      "source": [
        "#Tfidfvector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVAwWRxCc-li"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "v = TfidfVectorizer()\n",
        "x = v.fit_transform(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6nzJOQE2zVX"
      },
      "source": [
        "#Dataset division"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvHzKidneDIJ"
      },
      "source": [
        "# dividing the data into test and train set\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test, y_train, y_test=train_test_split(x,y,test_size=0.3, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwgMZibekOG9"
      },
      "source": [
        "dict_models={}\n",
        "dict_accuracy={}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoY4K88q2c8s"
      },
      "source": [
        "#Model-1, MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HQn4f3EeN2s",
        "outputId": "af26f0fc-70ba-4311-a395-f1f7b6712156"
      },
      "source": [
        "#model-1\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "classifier_mnb=MultinomialNB()\n",
        "classifier_mnb.fit(x_train, y_train)\n",
        "pred = classifier_mnb.predict(x_test)\n",
        "score = accuracy_score(y_test, pred)\n",
        "print(\"accuracy:   %0.3f\" % score)\n",
        "print()\n",
        "print(\"accuracy_matrix\")\n",
        "print(confusion_matrix(y_test,pred))\n",
        "print()\n",
        "print(f\"Classification Report : \\n\\n{classification_report(y_test, pred)}\")\n",
        "dict_models[\"MultinomialNB\"]=classifier_mnb\n",
        "dict_accuracy[score]=\"MultinomialNB\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:   0.871\n",
            "\n",
            "accuracy_matrix\n",
            "[[3055   29]\n",
            " [ 775 2381]]\n",
            "\n",
            "Classification Report : \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.99      0.88      3084\n",
            "           1       0.99      0.75      0.86      3156\n",
            "\n",
            "    accuracy                           0.87      6240\n",
            "   macro avg       0.89      0.87      0.87      6240\n",
            "weighted avg       0.89      0.87      0.87      6240\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpM66YZL3e2j"
      },
      "source": [
        "#Tuning of MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lJRbt3De-Vp",
        "outputId": "3a2762ff-2a77-4b0e-c35e-21029dedbba0"
      },
      "source": [
        "## tuning with different values of k, also know as add k smoothing\n",
        "import numpy as np\n",
        "pre_score=0\n",
        "best_k=0\n",
        "mnb_tuned_classfier=MultinomialNB()\n",
        "for a in np.arange(0, 2, 0.1):\n",
        "  classifier=MultinomialNB(alpha=a)\n",
        "  classifier.fit(x_train,y_train)\n",
        "  pred = classifier.predict(x_test)\n",
        "  score = accuracy_score(y_test, pred)\n",
        "  if(score>pre_score):\n",
        "    mnb_tuned_classifier=classifier\n",
        "    pre_score=score\n",
        "    best_k=a\n",
        "\n",
        "mnb_tuned_classifier.fit(x_train,y_train)\n",
        "pred = mnb_tuned_classifier.predict(x_test)\n",
        "score = accuracy_score(y_test, pred)\n",
        "print(\"accuracy: %0.3f\" %score)\n",
        "print(\"best_k: %0.3f\" % best_k)\n",
        "print()\n",
        "print(\"accuracy_matrix\")\n",
        "print(confusion_matrix(y_test,pred))\n",
        "print()\n",
        "print(f\"Classification Report : \\n\\n{classification_report(y_test, pred)}\")\n",
        "dict_models[\"Tuned_MultinomialNB\"]=classifier_mnb\n",
        "dict_accuracy[score]=\"Tuned_MultinomialNB\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:557: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  % _ALPHA_MIN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.921\n",
            "best_k: 0.100\n",
            "\n",
            "accuracy_matrix\n",
            "[[2978  106]\n",
            " [ 387 2769]]\n",
            "\n",
            "Classification Report : \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.97      0.92      3084\n",
            "           1       0.96      0.88      0.92      3156\n",
            "\n",
            "    accuracy                           0.92      6240\n",
            "   macro avg       0.92      0.92      0.92      6240\n",
            "weighted avg       0.92      0.92      0.92      6240\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAASE_3V2Vat"
      },
      "source": [
        "#Model-3 PassiveAggresive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56tNE223fu0Y",
        "outputId": "ec3ddb2f-c7e1-4dbc-cc60-d5fbe4400eff"
      },
      "source": [
        "#model 3\n",
        "\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "model_pa = PassiveAggressiveClassifier(C = 0.6, random_state = 5)\n",
        "model_pa.fit(x_train, y_train)\n",
        "test_pred = model_pa.predict(x_test)\n",
        "score = accuracy_score(y_test, test_pred)\n",
        "print(f\"Tuned Test Set Accuracy : {accuracy_score(y_test, test_pred) * 100} %\\n\\n\")  \n",
        "print()\n",
        "print(\"accuracy_matrix\")\n",
        "print(confusion_matrix(y_test,test_pred))\n",
        "print()\n",
        "print(f\"Classification Report : \\n\\n{classification_report(y_test, test_pred)}\")\n",
        "dict_models[\"passive_aggresive\"]=model_pa\n",
        "dict_accuracy[score]=\"passive_aggresive\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Accuracy : 97.25961538461539 %\n",
            "\n",
            "\n",
            "\n",
            "accuracy_matrix\n",
            "[[2977  107]\n",
            " [  64 3092]]\n",
            "\n",
            "Classification Report : \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97      3084\n",
            "           1       0.97      0.98      0.97      3156\n",
            "\n",
            "    accuracy                           0.97      6240\n",
            "   macro avg       0.97      0.97      0.97      6240\n",
            "weighted avg       0.97      0.97      0.97      6240\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV2HxLgi17t9"
      },
      "source": [
        "# Model-3, Decision Tree\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm64jtAqhCfq"
      },
      "source": [
        "#model-3\n",
        "#decission tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt_classifier=DecisionTreeClassifier()\n",
        "dt_classifier.fit(x_train,y_train)\n",
        "test_pred = dt_classifier.predict(x_test)\n",
        "score=accuracy_score(y_test, test_pred)\n",
        "print(f\"Test Set Accuracy : {accuracy_score(y_test, test_pred) * 100} %\\n\\n\")\n",
        "print()\n",
        "print(\"accuracy_matrix\")\n",
        "print(confusion_matrix(y_test,test_pred))\n",
        "print()\n",
        "print(f\"Classification Report : \\n\\n{classification_report(y_test, test_pred)}\")\n",
        "  \n",
        "#dict_models[\"DecisionTree\"]=dt_classifier\n",
        "#dict_accuracy[score]=\"DecisionTree\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9foSItN10Um"
      },
      "source": [
        "#Model-4, RANDOM FOREST\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "za_3jO2aidCy",
        "outputId": "17f110a1-f7f3-4ccc-d432-70525e655304"
      },
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf_random= RandomForestClassifier()\n",
        "clf_random.fit(x_train, y_train)\n",
        "pred = clf_random.predict(x_test)\n",
        "score = accuracy_score(y_test, pred)\n",
        "print(\"accuracy:   %0.3f\" % score)\n",
        "print()\n",
        "print(\"accuracy_matrix\")\n",
        "print(confusion_matrix(y_test,pred))\n",
        "print()\n",
        "print(f\"Classification Report : \\n\\n{classification_report(y_test, pred)}\")\n",
        "\n",
        "dict_models[\"RandomForestClassifier\"]=clf_random\n",
        "dict_accuracy[score]=\"RandomForestClassifier\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:   0.941\n",
            "\n",
            "accuracy_matrix\n",
            "[[2963  121]\n",
            " [ 247 2909]]\n",
            "\n",
            "Classification Report : \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94      3084\n",
            "           1       0.96      0.92      0.94      3156\n",
            "\n",
            "    accuracy                           0.94      6240\n",
            "   macro avg       0.94      0.94      0.94      6240\n",
            "weighted avg       0.94      0.94      0.94      6240\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK1tNh9K1n3Z"
      },
      "source": [
        "#Model-5, LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NPUhYKohn_E"
      },
      "source": [
        "# we use one hot vector for obtaining the positional embeddings.\n",
        "# we have conidered sequential model to help the model learn context and produce better results\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "vocab_size=5000\n",
        "onehot_rep=[one_hot(w,vocab_size) for w in data]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A90OxyBliCHD",
        "outputId": "8c1a6b46-deb0-4f3b-f891-6227c83f84cc"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense\n",
        "from tensorflow.keras.layers import LSTM,Bidirectional, Dropout\n",
        "embd=pad_sequences(onehot_rep,padding='pre', maxlen=650)\n",
        "embd.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20800, 650)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ve3ilC1sjhct",
        "outputId": "4896b788-1128-413e-8966-cf4617eadb87"
      },
      "source": [
        "#creating model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 40, input_length=650))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 650, 40)           200000    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 650, 40)           0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 50)                18200     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                3264      \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 221,529\n",
            "Trainable params: 221,529\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hF0dd3Wuj7Xo",
        "outputId": "10ef6cee-9620-4d8b-bfe1-194a7a2e982a"
      },
      "source": [
        "x_final=np.array(embd)\n",
        "y_final=np.array(y)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_final, y_final, test_size=0.2)\n",
        "model.fit(x_train,y_train,epochs=5,batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "260/260 [==============================] - 111s 417ms/step - loss: 0.3211 - accuracy: 0.8621\n",
            "Epoch 2/5\n",
            "260/260 [==============================] - 108s 416ms/step - loss: 0.1495 - accuracy: 0.9508\n",
            "Epoch 3/5\n",
            "260/260 [==============================] - 109s 420ms/step - loss: 0.1137 - accuracy: 0.9632\n",
            "Epoch 4/5\n",
            "260/260 [==============================] - 109s 418ms/step - loss: 0.0874 - accuracy: 0.9712\n",
            "Epoch 5/5\n",
            "260/260 [==============================] - 109s 419ms/step - loss: 0.0539 - accuracy: 0.9832\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc45e3fe310>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1KkZtHHkGM8",
        "outputId": "9bd05675-9f52-4c3b-99c6-c498872455d8"
      },
      "source": [
        "y_pred=(model.predict(x_test)>=0.5).astype(int)\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print()\n",
        "print(\"accuracy_matrix\")\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print()\n",
        "print(f\"Classification Report : \\n\\n{classification_report(y_test, y_pred)}\")\n",
        "dict_models[\"lstm\"]=model\n",
        "dict_accuracy[score]=\"lstm\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9447115384615384\n",
            "\n",
            "accuracy_matrix\n",
            "[[1974  129]\n",
            " [ 101 1956]]\n",
            "\n",
            "Classification Report : \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.94      2103\n",
            "           1       0.94      0.95      0.94      2057\n",
            "\n",
            "    accuracy                           0.94      4160\n",
            "   macro avg       0.94      0.94      0.94      4160\n",
            "weighted avg       0.94      0.94      0.94      4160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "612pfcuK1a_K"
      },
      "source": [
        "#finding model with highest accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7w-MD3XxDH7",
        "outputId": "3cecea36-9497-421b-efa2-745063f6e183"
      },
      "source": [
        "keys=dict_accuracy.keys()\n",
        "max_key=max(keys)\n",
        "print(keys)\n",
        "model_name=dict_accuracy[max_key]\n",
        "print(model_name)\n",
        "model=dict_models[model_name]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys([0.8711538461538462, 0.9209935897435897, 0.9725961538461538, 0.9625, 0.941025641025641])\n",
            "passive_aggresive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI0p7Z6VxRTw",
        "outputId": "b09e6829-d860-4458-d476-27585568cf3b"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassiveAggressiveClassifier(C=0.6, random_state=5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE4wf-SW32rw"
      },
      "source": [
        "#saving the model and TF idf vector for deployment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-GHOSG03zz2"
      },
      "source": [
        " import pickle\n",
        "pickle.dump(model, open('/content/drive/MyDrive/models/model.pickle', 'wb'))\n",
        "pickle.dump(v,open('/content/drive/MyDrive/models/tfidf.pickle', 'wb'))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}